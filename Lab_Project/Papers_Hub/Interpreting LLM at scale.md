---
Status: To read
---
# Interpreting LLM at scale 
[Mor Geva](https://scholar.google.com/citations?user=GxpQbSkAAAAJ&hl=en)

# Background
We are having a hard time interpreting the feature or understand their meaning 
- How to interpret 
- How to evaluate
- How to scale
This task was seen before but as the LLM's scaled we had to put it aside.
Disetntage DAS SAE
[Attention Heads](https://openreview.net/pdf?id=kvcbV8KQsi) 

## Leading Questions
Can we map a specific attention head for its functionality given its parameters?

> *Sneak peek to results is that we showed that given parameters we can derive information without the input *

# Method / Model

Add text here
[Paper on the emedding of attention head and deriving from it ](https://arxiv.org/pdf/2209.02535)


First we have to collect a relation dataset 
Casusal Expirment
- Craft a specific test ( the capital of<> is _
-  Remove relational heads and check the difference in preformance
[paper](https://arxiv.org/pdf/2203.14680)
# Results

The paper : [here](https://arxiv.org/pdf/2412.11965)
הרעיון המרכזי הוא בעצם הטלה לעולם המילון ואנו שמים לב שראשים בשכבות האחרונות משפיעות רבות על זה.

# Code

Add link to code here (if exists)