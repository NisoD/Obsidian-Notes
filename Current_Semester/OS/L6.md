# Scheduler
## Input
- The jobs to schedule
## Output
- The specific job that will run
## Objective
- No hunger for a specific job
- Good throughput
## What are the available actions
- Context switch and prioritization
> We want to improve wait-time 
### We have multiple objectives
- High CPU utilization
- High throughput
> Both of them are highly affected by availability of jobs and usage
> Also limited when we have overload
## Off-Line vs Online
At online setting we can't know what is coming and we have to predict.
### Offline
We have list of jobs that we know of.
We know how much is each job
#### Simplest apparoach
FCFS - First come first serve
We have very high wait time.
> When talking about wait time we are interested in Averages
This approach has high avg response time and waiting time.
##### Problem - "Convoy effect"
Short jobs get stuck behind the long ones.
#### Solution SJF - Run the short ones first 
Sort by runtime, not an optimal solution but improves wait time
> Can we improve it? - Not really
##### Proof of optimality for avg wait time
Assume via contradiction that we have a schedule S that has optimal avg time
We can switch two jobs to improve but if we do than the avg waitime increases


### Online
Use FCFS again but now we don't know runtime of each job.
#### Priority schedule
In FCFS priority = time since arrival
IN SJF priority = 1/runtime of a job
### SJF Suffers from a problem 
An online algorithm doesn't know the runtime.
- We can assume preemption 
#### Solution SRPT - Shortest remaining processing time
We do context switch according to new arrivals via remaining runtime.

### Realistic approach
Job runtime is not known in advance
We can use preemption
> We can learn during our run
#### Estimate
$t_n =actual length of n^th cpu burst$
$i_{n+1} = predicted value$
## Processor Sharing
I didn't write the realistic approach input here

## Data
most process are very short
some are very long
the distribution has Pareto tail
$Pr(r>t)=\frac{1}{t}$
Processor sharing should be good
## Solution RR Scheduling Round Robin
Approximation of processor sharing
Run each process for a certain time quantum
E.g usually 10-100 ms
The con is a very high amount of context switches.
when n jobs and quantum q than no jobwaits more than (n-1)q
if context switch takes c time overhead will be $c/(q+c)$
if q is long bursts will finish before end of quantum it leads to act like FCFS.

> It's hard to evaluate the performance of such algorithm and it's success as usage varies 

Round robin works well with lack of knowledge
RR gives uniform tearment to all jobs.

