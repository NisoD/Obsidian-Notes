---
TOPIC: NLP
CLASS MODE: LECTURE
Completed: false
WEEK: WEEK 1
---
#### Synthetic vs Real World data
We can recognize an orthogonal relationship between the type of task and synthetic vs real world data.
#### Task vs Format
The way we present a task to a model changes the way it preforms on the task

#### Recognizing Textual Entailment - RTE
Given a text decide whether one text is inferred from another text.
We have :
1. Premise
2. Hypothesis
3. Label - Natural, Contradiction, Entailment, Premise
> SNLI - Yearly Challenge for RTE with Synthetic Data

Problem many times the model learns the annotators style
####  Co reference
Revolves around **grounding** 
Mapping from text to a world action or common understanding
Emily Bender [Emily](https://www.google.com/search?client=ubuntu-sn&hs=1P3&sca_esv=f7eed69fd92caa42&channel=fs&q=emily+bender&sa=X&ved=2ahUKEwjZj_fYiqCMAxV8gP0HHat6KpEQ7xYoAHoECAwQAQ&biw=1373&bih=654&dpr=1.4)
החדר הסיני -  יש אדם שלא יודע סינית 
==The Chinese room argument holds that a computer executing a program cannot have a mind, understanding, or consciousness, regardless of how intelligently or human-like the program may make the computer behave.==
The text is to extract  Co reference clusters,
**Ontology** - Out of text for example Wikipedia
Format is Wingorad Schema when we take two text changes via very small tweaks 


Example of ontologys CADEC AIDA CONLL-YAGO
### Downstream Tasks

Extractive Summarization
#### Information Extraction
A lot of times scientist want to extract information from big corpus for quick analysis
> Today nip doesn't require pipeline but rather and End 2 End approach/
Open Question - Why do we need intersintic tasks ?
E2E improves without, the need of inersintic tasks.





