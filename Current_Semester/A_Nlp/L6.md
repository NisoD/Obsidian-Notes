# Theoretical Analysis
There is a mathematical guarantees about their behavior
> Can we infer a-priori properties from LLM?

## Research question - How does In-Context learning work?
LLM's implicitly learn to preform gradient descent via the attention mechanism
[Paper](https://arxiv.org/pdf/2212.10559)
### Assumption that might interfere:
- Linearity
- Neat order

---
# The cognitive approach to NN
## Learning In Humans
Humans can learn skills and apply them
> How to distinguish learning a skill and applying it.

In neuroscience learning is connected to neural plasticity.
The correlation is associated to updating weights

### Gili - computation or weight adaption
Examine LLM on tasks which require biological plasticity.
i.e
- Statistical learning

> Can LLMs perform such task without plasticity
We might think that models fail on this task
However we see models able to succeed in such tasks.

The work shows that a model is able to do in-context learning to apply on probabilistic.

### Cognitive and societal biases
Do llms exhibit similar patterns?
Itay's work shows that GPT3 has no bias, however adding instruct and RLHF signifies the biases.

Fine-tuned models are more biased.
# Consciousness
LLMs mimic human behaviour 
> Do they really **understand** text?
This debate revolves around consiousness





