# Finetuning
we can finetune a whole model via HF 
## Truncation and padding
Models has token  number limit which we have to stick to
- Truncate 
- Padding
Solutions can be:
- Pad to the longest
### Static Padding
Uses [HF-REF](https://huggingface.co/docs/transformers/pad_truncation)
Please create a requirments file.
Use google cloud with drive mount to avoid deletion of runtime.
### Weights and biases
A tool for multiple expeirments 
sign up at - [here](https://wandb.ai/site)
